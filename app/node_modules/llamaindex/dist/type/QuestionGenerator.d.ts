import type { LLM, ToolMetadata } from "@llamaindex/core/llms";
import { type ModuleRecord, PromptMixin, type SubQuestionPrompt } from "@llamaindex/core/prompts";
import type { QueryType } from "@llamaindex/core/query-engine";
import type { BaseOutputParser } from "@llamaindex/core/schema";
import type { BaseQuestionGenerator, SubQuestion } from "./engines/query/types.js";
import type { StructuredOutput } from "./types.js";
/**
 * LLMQuestionGenerator uses the LLM to generate new questions for the LLM using tools and a user query.
 */
export declare class LLMQuestionGenerator extends PromptMixin implements BaseQuestionGenerator {
    llm: LLM;
    prompt: SubQuestionPrompt;
    outputParser: BaseOutputParser<StructuredOutput<SubQuestion[]>>;
    constructor(init?: Partial<LLMQuestionGenerator>);
    protected _getPrompts(): {
        [x: string]: SubQuestionPrompt;
    };
    protected _updatePrompts(promptsDict: {
        subQuestion: SubQuestionPrompt;
    }): void;
    generate(tools: ToolMetadata[], query: QueryType): Promise<SubQuestion[]>;
    protected _getPromptModules(): ModuleRecord;
}
