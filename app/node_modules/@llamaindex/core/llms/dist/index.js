import { streamConverter } from '../../utils/dist/index.js';
import '@llamaindex/env';
import 'magic-bytes.js';

/**
 * Extracts just the text whether from
 *  a multi-modal message
 *  a single text message
 *  or a query
 *
 * @param message The message to extract text from.
 * @returns The extracted text
 */ function extractText(message) {
    if (typeof message === "object" && "query" in message) {
        return extractText(message.query);
    }
    if (typeof message !== "string" && !Array.isArray(message)) {
        console.warn("extractText called with non-MessageContent message, this is likely a bug.");
        return `${message}`;
    } else if (typeof message !== "string" && Array.isArray(message)) {
        // message is of type MessageContentDetail[] - retrieve just the text parts and concatenate them
        // so we can pass them to the context generator
        return message.filter((c)=>c.type === "text").map((c)=>c.text).join("\n\n");
    } else {
        return message;
    }
}

class BaseLLM {
    async complete(params) {
        const { prompt, stream } = params;
        if (stream) {
            const stream = await this.chat({
                messages: [
                    {
                        content: prompt,
                        role: "user"
                    }
                ],
                stream: true
            });
            return streamConverter(stream, (chunk)=>{
                return {
                    raw: null,
                    text: chunk.delta
                };
            });
        }
        const chatResponse = await this.chat({
            messages: [
                {
                    content: prompt,
                    role: "user"
                }
            ]
        });
        return {
            text: extractText(chatResponse.message.content),
            raw: chatResponse.raw
        };
    }
}
class ToolCallLLM extends BaseLLM {
}

export { BaseLLM, ToolCallLLM };
