import { MultiModalEmbedding } from '@llamaindex/core/embeddings';
import { ImageType } from '@llamaindex/core/schema';
import { LoadTransformerEvent } from '@llamaindex/env';
import { PreTrainedTokenizer, Processor, CLIPVisionModelWithProjection, CLIPTextModelWithProjection } from '@xenova/transformers';

declare enum ClipEmbeddingModelType {
    XENOVA_CLIP_VIT_BASE_PATCH32 = "Xenova/clip-vit-base-patch32",
    XENOVA_CLIP_VIT_BASE_PATCH16 = "Xenova/clip-vit-base-patch16"
}

declare module "@llamaindex/core/global" {
    interface LlamaIndexEventMaps {
        "load-transformers": LoadTransformerEvent;
    }
}
declare class ClipEmbedding extends MultiModalEmbedding {
    modelType: ClipEmbeddingModelType;
    private tokenizer;
    private processor;
    private visionModel;
    private textModel;
    constructor();
    getTokenizer(): Promise<PreTrainedTokenizer>;
    getProcessor(): Promise<Processor>;
    getVisionModel(): Promise<CLIPVisionModelWithProjection>;
    getTextModel(): Promise<CLIPTextModelWithProjection>;
    getImageEmbedding(image: ImageType): Promise<number[]>;
    getTextEmbedding(text: string): Promise<number[]>;
}

export { ClipEmbedding, ClipEmbeddingModelType };
