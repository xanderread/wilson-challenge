import { LLMAgentParams, LLMAgentWorker, LLMAgent } from '@llamaindex/core/agent';
import { NonStreamingChatEngineParams, StreamingChatEngineParams } from '@llamaindex/core/chat-engine';
import { EngineResponse } from '@llamaindex/core/schema';
import { Anthropic as Anthropic$1, ClientOptions } from '@anthropic-ai/sdk';
import { MessageParam, Tool } from '@anthropic-ai/sdk/resources/messages';
import { ToolCallLLM, ChatMessage, ToolCallLLMMessageOptions, LLMChatParamsStreaming, ChatResponseChunk, LLMChatParamsNonStreaming, ChatResponse, BaseTool } from '@llamaindex/core/llms';

type AnthropicAgentParams = LLMAgentParams;
declare class AnthropicAgentWorker extends LLMAgentWorker {
}
declare class AnthropicAgent extends LLMAgent {
    constructor(params: AnthropicAgentParams);
    chat(params: NonStreamingChatEngineParams): Promise<EngineResponse>;
    chat(params: StreamingChatEngineParams): Promise<never>;
}

declare class AnthropicSession {
    anthropic: Anthropic$1;
    constructor(options?: ClientOptions);
}
declare const ALL_AVAILABLE_ANTHROPIC_LEGACY_MODELS: {
    "claude-2.1": {
        contextWindow: number;
    };
    "claude-instant-1.2": {
        contextWindow: number;
    };
};
declare const ALL_AVAILABLE_V3_MODELS: {
    "claude-3-opus": {
        contextWindow: number;
    };
    "claude-3-sonnet": {
        contextWindow: number;
    };
    "claude-3-haiku": {
        contextWindow: number;
    };
};
declare const ALL_AVAILABLE_V3_5_MODELS: {
    "claude-3-5-sonnet": {
        contextWindow: number;
    };
};
declare const ALL_AVAILABLE_ANTHROPIC_MODELS: {
    "claude-3-5-sonnet": {
        contextWindow: number;
    };
    "claude-3-opus": {
        contextWindow: number;
    };
    "claude-3-sonnet": {
        contextWindow: number;
    };
    "claude-3-haiku": {
        contextWindow: number;
    };
    "claude-2.1": {
        contextWindow: number;
    };
    "claude-instant-1.2": {
        contextWindow: number;
    };
};
type AnthropicAdditionalChatOptions = {};
declare class Anthropic extends ToolCallLLM<AnthropicAdditionalChatOptions> {
    model: keyof typeof ALL_AVAILABLE_ANTHROPIC_MODELS;
    temperature: number;
    topP: number;
    maxTokens?: number | undefined;
    apiKey?: string | undefined;
    maxRetries: number;
    timeout?: number;
    session: AnthropicSession;
    constructor(init?: Partial<Anthropic>);
    get supportToolCall(): boolean;
    get metadata(): {
        model: "claude-3-5-sonnet" | "claude-3-opus" | "claude-3-sonnet" | "claude-3-haiku" | "claude-2.1" | "claude-instant-1.2";
        temperature: number;
        topP: number;
        maxTokens: number | undefined;
        contextWindow: number;
        tokenizer: undefined;
    };
    getModelName: (model: string) => string;
    formatMessages(messages: ChatMessage<ToolCallLLMMessageOptions>[]): MessageParam[];
    chat(params: LLMChatParamsStreaming<AnthropicAdditionalChatOptions, ToolCallLLMMessageOptions>): Promise<AsyncIterable<ChatResponseChunk<ToolCallLLMMessageOptions>>>;
    chat(params: LLMChatParamsNonStreaming<AnthropicAdditionalChatOptions, ToolCallLLMMessageOptions>): Promise<ChatResponse<ToolCallLLMMessageOptions>>;
    protected streamChat(messages: ChatMessage<ToolCallLLMMessageOptions>[], systemPrompt?: string | null): AsyncIterable<ChatResponseChunk<ToolCallLLMMessageOptions>>;
    static toTool(tool: BaseTool): Tool;
}

export { ALL_AVAILABLE_ANTHROPIC_LEGACY_MODELS, ALL_AVAILABLE_ANTHROPIC_MODELS, ALL_AVAILABLE_V3_5_MODELS, ALL_AVAILABLE_V3_MODELS, Anthropic, type AnthropicAdditionalChatOptions, AnthropicAgent, type AnthropicAgentParams, AnthropicAgentWorker, AnthropicSession };
